This project implements the linear search algorithm to analyze its performance in three scenarios: best case, average case, and worst case. For different input sizes, random integers are generated, and time taken for each case is measured in milliseconds. A line graph is plotted to compare the time complexity for all three cases. This helps understand why best case is O(1), average case is O(n/2), and worst case is O(n), and how the execution time increases with input size.
